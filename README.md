ğŸ’³ Fraud Detection using Machine Learning (IEEE-CIS Dataset)
ğŸš€ Overview

This project focuses on detecting fraudulent transactions using Machine Learning, leveraging the IEEE-CIS Fraud Detection dataset from Kaggle.
Fraud detection is a critical problem in the financial industry, and this project demonstrates how data preprocessing, feature engineering, and model optimization can work together to build an effective fraud detection system.

ğŸ§  Project Objective

The goal of this project is to classify online transactions as fraudulent or genuine using machine learning â€” specifically, the XGBoost algorithm, which is highly efficient for imbalanced classification problems.

ğŸ“Š Dataset

Source: IEEE-CIS Fraud Detection Dataset (Kaggle)

This dataset contains transaction-level data, including numerical, categorical, and identity-based features.
Key details:

Rows: ~590K+ transactions

Features: Transaction amount, card details, product codes, device info, and more

Target: isFraud (1 â†’ Fraudulent, 0 â†’ Genuine)

âš™ï¸ Workflow

The project follows a structured data science pipeline:

1ï¸âƒ£ Data Preprocessing

Handled missing values using median imputation for numeric columns

Dropped irrelevant columns (like TransactionID)

Encoded categorical variables using Label Encoding

Performed outlier analysis to stabilize the distribution

2ï¸âƒ£ Exploratory Data Analysis (EDA)

Visualized feature distributions and fraud frequency

Identified relationships between transaction amount, time, and fraud likelihood

Examined correlations to detect redundant features

3ï¸âƒ£ Feature Engineering

Created new derived features like TransactionAmt_to_mean_card1

Normalized skewed numerical features

Balanced the dataset using undersampling/oversampling techniques

4ï¸âƒ£ Model Training (XGBoost)

Implemented the XGBoost classifier, tuned hyperparameters using GridSearchCV

Used early stopping to avoid overfitting

Trained the model on preprocessed data

5ï¸âƒ£ Model Evaluation

Evaluated using:

Accuracy

Precision / Recall / F1-score

ROC-AUC Curve

Focused on Recall and F1-score, since false negatives (missed frauds) are costlier than false positives.

ğŸ“ˆ Results

Model Used: XGBoost

Accuracy: ~99%

ROC-AUC Score: ~0.97

The model effectively distinguishes between fraudulent and non-fraudulent transactions with minimal false negatives.

ğŸ§© Tech Stack

Language: Python ğŸ

Libraries:

pandas, numpy, matplotlib, seaborn â€” for data processing and visualization

scikit-learn â€” for preprocessing and evaluation

xgboost â€” for model training and tuning

joblib â€” for model saving

ğŸ–¥ï¸ Folder Structure
Fraud_Detection/
â”‚
â”œâ”€â”€ fraud_detection_model.ipynb    # Main notebook
â”œâ”€â”€ data/                          # Dataset folder (not included due to size)
â”œâ”€â”€ models/                        # Saved models (XGBoost)
â”œâ”€â”€ README.md                      # Project documentation
â””â”€â”€ requirements.txt               # Dependencies

âš¡ Future Work

ğŸŒ Build a Streamlit-based web app for real-time fraud prediction

ğŸ“¦ Deploy the model using Flask + AWS

ğŸ“Š Add SHAP explainability to understand feature importance

ğŸ§© Implement deep learning models (like LSTM for temporal features)

ğŸ§¾ Key Learnings

Handling missing data with appropriate strategies (median imputation)

Understanding the impact of outliers on mean vs. median

Tackling imbalanced datasets effectively

Using XGBoost for high-dimensional, tabular data

ğŸ§‘â€ğŸ’» Author

Rahul Gupta
ğŸ“ B.Tech â€“ Computer Science | SRM Institute of Science and Technology
ğŸ’¼ Aspiring Machine Learning & Backend Engineer
ğŸ”— LinkedIn
 | GitHub

ğŸ“œ License

This project is licensed under the MIT License â€” feel free to use, modify, and build upon it for your own learning or projects.
